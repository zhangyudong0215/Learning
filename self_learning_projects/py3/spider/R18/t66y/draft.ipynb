{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "import regex\n",
    "from functools import partial\n",
    "from tqdm import tqdm, tgrange, tnrange\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlsession = HTMLSession()\n",
    "\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "    'accept': 'text/html, application/xhtml+xml, application/xml; q=0.9, image/webp, */*; q=0.8', \n",
    "    'referer': 'http://t66y.com/index.php'\n",
    "}\n",
    "\n",
    "proxies = {\n",
    "    'http': 'http://127.0.0.1:1080/',\n",
    "    'https': 'http://127.0.0.1:1080/', \n",
    "}\n",
    "\n",
    "base_url = 'http://t66y.com/thread0806.php?fid=20'\n",
    "\n",
    "pattern = 'http://t66y\\.com/htm_data/20/\\d+/\\d+\\.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response = partial(htmlsession.get, proxies=proxies, headers=headers)\n",
    "\n",
    "def get_page_count(res):\n",
    "    page_count = res.html.find('a.w70', first=True).find('input', first=True).attrs['value'].split('/')[-1]\n",
    "    return int(page_count)\n",
    "\n",
    "def get_page_urls(page_count):    \n",
    "    base_page_url = 'http://t66y.com/thread0806.php?fid=20&search=&page='\n",
    "    page_urls = [base_page_url+str(i) for i in range(2, page_count+1)]\n",
    "    return page_urls\n",
    "\n",
    "def get_novel_urls(res):\n",
    "    novel_urls =  [link for link in res.html.absolute_links if regex.match(pattern, link)]\n",
    "    return novel_urls\n",
    "\n",
    "def get_first_page_details(res):\n",
    "    text = ''\n",
    "    tag = res.html.find('div[class=\"t t2\"]')\n",
    "    for element in tag:\n",
    "        reply = element.find('div[class=\"tpc_content do_not_catch\"]', first=True).text\n",
    "        if len(reply) > 100:\n",
    "            text += reply + '\\n'\n",
    "    return text\n",
    "\n",
    "def get_page_details(res):\n",
    "    text = ''\n",
    "    tag = res.html.find('div[class=\"t t2\"]')\n",
    "    for element in tag:\n",
    "        reply = element.find('div[class=\"tpc_content\"]', first=True).text\n",
    "        if len(reply) > 100:\n",
    "            text += reply + '\\n'\n",
    "    return text\n",
    "\n",
    "def get_details(novel_url):\n",
    "    novel_id = novel_url.split('/')[-1][: -5]\n",
    "    res = get_response(novel_url)\n",
    "    title = res.html.find('input[class=\"input\"]', first=True).attrs['value'].replace('Re:', '')\n",
    "    page_count = get_page_count(res)\n",
    "    \n",
    "    text = get_first_page_details(res)\n",
    "    base = 'http://t66y.com/read.php?tid={novel_id}&fpage=0&toread=&page='.format(novel_id=novel_id)\n",
    "    for i in range(2, page_count+1):\n",
    "        page_url = base + str(i)\n",
    "        res = get_response(page_url)\n",
    "        text += get_page_details(res)\n",
    "    return title, text\n",
    "\n",
    "def save(title, text):\n",
    "    with open('novels/{title}.txt'.format(title=title), 'w') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "#     res = get_response(base_url)\n",
    "#     page_count = get_page_count(res)\n",
    "#     page_urls = get_page_urls(page_count)\n",
    "    \n",
    "#     novel_urls = get_novel_url(res)\n",
    "#     for url in tqdm(page_urls):\n",
    "#         res = get_response(url)\n",
    "#         novel_urls.extend(get_novel_urls(res))\n",
    "# #             time.sleep(1)\n",
    "#     novel_urls = list(set(novel_urls))\n",
    "\n",
    "#     with open('novel_urls.txt', 'wb') as f:\n",
    "#         pickle.dump(novel_urls, f)\n",
    "\n",
    "    with open('novel_urls.txt', 'rb') as f:\n",
    "        novel_urls = pickle.load(f)\n",
    "    \n",
    "    for novel_url in tqdm(novel_urls):\n",
    "        title, text = get_details(novel_url)\n",
    "        save(title, text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
