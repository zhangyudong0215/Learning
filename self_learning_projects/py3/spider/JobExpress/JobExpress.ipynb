{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小百合JobExpress板块信息\n",
    "+ 储存到阿里云mysql中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "import regex as re\n",
    "import string\n",
    "import time\n",
    "from mylog import MyLog as mylog\n",
    "import pymysql\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUCCESSES = 0\n",
    "ERRORS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = mylog()\n",
    "htmlsession = HTMLSession()\n",
    "headers = {\n",
    "    'user-agent':\n",
    "    'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "    'accept':\n",
    "    'text/html, application/xhtml+xml, application/xml; q=0.9, image/webp, */*; q=0.8',\n",
    "    'referer':\n",
    "    'http://bbs.nju.edu.cn/g/JobExpress'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_url = 'http://bbs.nju.edu.cn/bbsdoc?board=JobExpress'\n",
    "pattern_index = re.compile('bbscon\\?board=JobExpress&file=M\\.(\\d+)\\.A&num=(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_going = True\n",
    "count_articles = 999999\n",
    "url_articles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymysql.connect(\"39.108.157.74\",\"root\",\"00genius00\",\"JobExpress\" )\n",
    "cursor = db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute(\"SELECT MAX(id) FROM links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_crawled = cursor.fetchone()[0]\n",
    "count_crawled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11914"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_crawled -= 100\n",
    "count_crawled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_url_articles(res):\n",
    "    global count_articles\n",
    "    global keep_going\n",
    "    global pattern_index\n",
    "    for link in res.html.links:\n",
    "        if link.startswith('bbscon?board=JobExpress&file=M.'):\n",
    "            index = int(pattern_index.match(link).group(2))\n",
    "            file = int(pattern_index.match(link).group(1))\n",
    "            if index > count_crawled:\n",
    "                count_articles = index if count_articles > index else count_articles\n",
    "                url_articles.append((str(file), str(index), 'http://bbs.nju.edu.cn/'+link))\n",
    "            else:\n",
    "                keep_going = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = htmlsession.get(start_url, headers=headers)\n",
    "update_url_articles(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "while keep_going:\n",
    "    count_articles = count_articles-20 if count_articles>=20 else 0\n",
    "    target_url = 'http://bbs.nju.edu.cn/bbsdoc?board=JobExpress&start=%s&type=doc' %str(count_articles)\n",
    "    res = htmlsession.get(target_url, headers=headers)\n",
    "    update_url_articles(res)\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert(cursor, db, file, index, url):\n",
    "    global SUCCESSES, ERRORS\n",
    "    sql_query = \"REPLACE INTO links VALUES ('%s', '%s', '%s')\" %(str(file), str(index), url)\n",
    "    try:\n",
    "        cursor.execute(sql_query)\n",
    "        db.commit()\n",
    "        logger.info('成功: 插入id为: %s 的招聘信息' %str(index))\n",
    "        SUCCESSES += 1\n",
    "    except:\n",
    "        db.rollback()\n",
    "        logger.error('失败: 插入id为: %s 的招聘信息' %str(index))\n",
    "        ERRORS += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in tqdm(url_articles):\n",
    "    insert(cursor, db, item[0], item[1], item[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 0\n"
     ]
    }
   ],
   "source": [
    "print(SUCCESSES, ERRORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二部分: 爬具体文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_html import HTMLSession\n",
    "import regex as re\n",
    "import string\n",
    "import time\n",
    "from mylog import MyLog as mylog\n",
    "import pymysql\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 1535419630\n",
    "id = 12000\n",
    "url = 'http://bbs.nju.edu.cn/bbscon?board=JobExpress&file=M.1535419630.A&num=12000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUCCESSES = 0\n",
    "# ERRORS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger = mylog()\n",
    "# htmlsession = HTMLSession()\n",
    "# headers = {\n",
    "#     'user-agent':\n",
    "#     'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "#     'accept':\n",
    "#     'text/html, application/xhtml+xml, application/xml; q=0.9, image/webp, */*; q=0.8',\n",
    "#     'referer':\n",
    "#     'http://bbs.nju.edu.cn/g/JobExpress'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = htmlsession.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags = res.html.find('td', first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern_user = re.compile('发信人: (.+?) \\((.+?)\\)')\n",
    "# pattern_clicks = re.compile('本篇人气: (\\d+)\\n')\n",
    "# pattern_title = re.compile('标  题: (.+?)\\n')\n",
    "# pattern_time = re.compile('发信站: 南京大学小百合站 \\((.+?) (.+?) (\\d+) (\\d{2}:\\d{2}:\\d{2}) (\\d+)\\)\\n\\n')\n",
    "# pattern_text = re.compile('发信站: 南京大学小百合站 \\(.+?\\)(.+?)--(.+?)来源')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jxhnpl 孤之剑未尝不利\n"
     ]
    }
   ],
   "source": [
    "# # user_id, user_name\n",
    "# re_user = pattern_user.search(tags.full_text)\n",
    "# user_id = re_user.group(1)\n",
    "# user_name = re_user.group(2)\n",
    "# print(user_id, user_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "# # clicks\n",
    "# re_clicks = pattern_clicks.search(tags.full_text)\n",
    "# clicks = re_clicks.group(1)\n",
    "# print(clicks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【汽车之家】商业产品/运营实习生\n"
     ]
    }
   ],
   "source": [
    "# # title\n",
    "# re_title = pattern_title.search(tags.full_text)\n",
    "# title = re_title.group(1)\n",
    "# print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 希望从事互联网行业，对商业化感兴趣的学弟学妹们不可错过~ 我们团队的实习生招聘，如果感兴趣，请邮件我简历~jiangxuehong@autohome.com.cn 岗位职责： 1、负责产品基础运营文档的维护更新； 2、承接业务部门广告投放需求，协助运营处理基础需求； 3、整理分析广告投放数据，完成日报周报等日常数据报告，协助运营同学把控广告效果； 4、协调内部资源，协助运营及产品进行线上问题处理跟进，促进产品迭代完善。 岗位要求： 1、本科及以上学历在读学生，可保证每周4个工作日及以上、连续4个月以上的实习时间； 2、对数据敏感，可以熟练操作excel、ppt等工具； 3、做事踏实认真，具备较强的快速学习能力、逻辑思维能力、执行力以及沟通协调能力； 4、有广告行业、商业化运营经验者优先。 \n"
     ]
    }
   ],
   "source": [
    "# # text\n",
    "# re_text = pattern_text.search(tags.text)\n",
    "# text = re_text.group(1)\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 28 09:27:10 2018\n"
     ]
    }
   ],
   "source": [
    "# # time\n",
    "# re_time = pattern_time.search(tags.full_text)\n",
    "# day, month, date, time, year = re_time.group(1), re_time.group(2), re_time.group(3), re_time.group(4), re_time.group(5)\n",
    "# print(day, month, date, time, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1535419630 12000 http://bbs.nju.edu.cn/bbscon?board=JobExpress&file=M.1535419630.A&num=12000\n"
     ]
    }
   ],
   "source": [
    "print(file, id, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(url):\n",
    "    res = htmlsession.get(url, headers=headers)\n",
    "    tags = res.html.find('td', first=True)\n",
    "    \n",
    "    # user_id, user_name\n",
    "    re_user = pattern_user.search(tags.full_text)\n",
    "    user_id = re_user.group(1)\n",
    "    user_name = re_user.group(2)\n",
    "\n",
    "    # clicks\n",
    "    re_clicks = pattern_clicks.search(tags.full_text)\n",
    "    clicks = re_clicks.group(1)\n",
    "\n",
    "    # title\n",
    "    re_title = pattern_title.search(tags.full_text)\n",
    "    title = re_title.group(1)\n",
    "\n",
    "    # time\n",
    "    try:\n",
    "        re_time = pattern_time.search(tags.full_text)\n",
    "        day, month, date, time, year = re_time.group(1), re_time.group(2), re_time.group(3), re_time.group(4), re_time.group(5)\n",
    "    except:\n",
    "        day, month, date, time, year = '', '', '', '', '' \n",
    "\n",
    "    # text\n",
    "    try:\n",
    "        re_text = pattern_text.search(tags.text)\n",
    "        text = re_text.group(1)\n",
    "    except:\n",
    "        text = ''\n",
    "    \n",
    "    return user_id, user_name, clicks, title, day, month, date, time, year, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global SUCCESSES\n",
    "    global ERRORS\n",
    "\n",
    "    logger = mylog()\n",
    "    htmlsession = HTMLSession()\n",
    "    headers = {\n",
    "        'user-agent':\n",
    "        'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:54.0) Gecko/20100101 Firefox/54.0',\n",
    "        'accept':\n",
    "        'text/html, application/xhtml+xml, application/xml; q=0.9, image/webp, */*; q=0.8',\n",
    "        'referer':\n",
    "        'http://bbs.nju.edu.cn/g/JobExpress'\n",
    "    }\n",
    "    \n",
    "    pattern_user = re.compile('发信人: (.+?) \\((.+?)\\)')\n",
    "    pattern_clicks = re.compile('本篇人气: (\\d+)\\n')\n",
    "    pattern_title = re.compile('标  题: (.+?)\\n')\n",
    "    pattern_time = re.compile('发信站: 南京大学小百合站 \\((.+?) (.+?) (\\d+) (\\d{2}:\\d{2}:\\d{2}) (\\d+)\\)\\n\\n')\n",
    "    pattern_text = re.compile('发信站: 南京大学小百合站 \\(.+?\\)(.+?)--(.+?)来源')\n",
    "    \n",
    "    db = pymysql.connect(\"39.108.157.74\",\"root\",\"00genius00\",\"JobExpress\" )\n",
    "    cursor = db.cursor()\n",
    "    \n",
    "    query = 'SELECT * FROM links WHERE crawled = 0 order by id desc limit 100;'\n",
    "    data = pd.read_sql_query(query, db)\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    for i in tqdm(range(len(data))):\n",
    "        try:\n",
    "            file, id, url = data.loc[i, ['file', 'id', 'links']]\n",
    "            user_id, user_name, clicks, title, day, month, date, time, year, text = get_details(url)\n",
    "\n",
    "            sql_query = \"REPLACE INTO details VALUES ('%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s')\" %(str(file), str(id), url, user_id, user_name, clicks, title, day, month, date, time, year, text)\n",
    "\n",
    "            try:\n",
    "                cursor.execute(sql_query)\n",
    "                cursor.execute('UPDATE links SET crawled = 1 WHERE file = %s and id = %s' %(file, id))\n",
    "                db.commit()\n",
    "                logger.info('成功: 爬取&插入id为: %s 的招聘信息' %str(id))\n",
    "                SUCCESSES += 1\n",
    "            except:\n",
    "                db.rollback()\n",
    "                logger.error('失败: 插入id为: %s 的招聘信息' %str(id))\n",
    "                ERRORS += 1\n",
    "        except:\n",
    "            logger.error('失败: 爬取id为: %s 的招聘信息' %str(id))\n",
    "    \n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                          | 0/100 [00:00<?, ?it/s]2018-08-29 01:16:47,060 ERROR    ydzhang    失败: 爬取id为: 12018 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:47,069 ERROR    ydzhang    失败: 爬取id为: 12017 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:47,191 INFO     ydzhang    成功: 爬取&插入id为: 12012 的招聘信息\n",
      "\n",
      "  3%|█▉                                                                | 3/100 [00:00<00:04, 21.57it/s]2018-08-29 01:16:47,367 INFO     ydzhang    成功: 爬取&插入id为: 12011 的招聘信息\n",
      "\n",
      "  4%|██▋                                                               | 4/100 [00:00<00:07, 12.68it/s]2018-08-29 01:16:47,493 INFO     ydzhang    成功: 爬取&插入id为: 12010 的招聘信息\n",
      "\n",
      "  5%|███▎                                                              | 5/100 [00:00<00:08, 11.33it/s]2018-08-29 01:16:47,617 INFO     ydzhang    成功: 爬取&插入id为: 12009 的招聘信息\n",
      "\n",
      "  6%|███▉                                                              | 6/100 [00:00<00:08, 10.61it/s]2018-08-29 01:16:47,745 INFO     ydzhang    成功: 爬取&插入id为: 12008 的招聘信息\n",
      "\n",
      "  7%|████▌                                                             | 7/100 [00:00<00:09, 10.09it/s]2018-08-29 01:16:47,878 INFO     ydzhang    成功: 爬取&插入id为: 12007 的招聘信息\n",
      "\n",
      "  8%|█████▎                                                            | 8/100 [00:00<00:09,  9.68it/s]2018-08-29 01:16:48,039 INFO     ydzhang    成功: 爬取&插入id为: 12006 的招聘信息\n",
      "\n",
      "  9%|█████▉                                                            | 9/100 [00:00<00:09,  9.11it/s]2018-08-29 01:16:48,161 INFO     ydzhang    成功: 爬取&插入id为: 12005 的招聘信息\n",
      "\n",
      " 10%|██████▌                                                          | 10/100 [00:01<00:09,  9.01it/s]2018-08-29 01:16:48,167 ERROR    ydzhang    失败: 爬取id为: 12004 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,174 ERROR    ydzhang    失败: 爬取id为: 12003 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,181 ERROR    ydzhang    失败: 爬取id为: 12002 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,188 ERROR    ydzhang    失败: 爬取id为: 12001 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,195 ERROR    ydzhang    失败: 爬取id为: 12000 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,201 ERROR    ydzhang    失败: 爬取id为: 11999 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,208 ERROR    ydzhang    失败: 爬取id为: 11998 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,214 ERROR    ydzhang    失败: 爬取id为: 11997 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,221 ERROR    ydzhang    失败: 爬取id为: 11996 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,227 ERROR    ydzhang    失败: 爬取id为: 11995 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,234 ERROR    ydzhang    失败: 爬取id为: 11994 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,241 ERROR    ydzhang    失败: 爬取id为: 11993 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,247 ERROR    ydzhang    失败: 爬取id为: 11992 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,254 ERROR    ydzhang    失败: 爬取id为: 11991 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,261 ERROR    ydzhang    失败: 爬取id为: 11990 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,267 ERROR    ydzhang    失败: 爬取id为: 11989 的招聘信息\n",
      "\n",
      " 26%|████████████████▉                                                | 26/100 [00:01<00:03, 21.40it/s]2018-08-29 01:16:48,274 ERROR    ydzhang    失败: 爬取id为: 11988 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,281 ERROR    ydzhang    失败: 爬取id为: 11987 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,287 ERROR    ydzhang    失败: 爬取id为: 11986 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,293 ERROR    ydzhang    失败: 爬取id为: 11985 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,299 ERROR    ydzhang    失败: 爬取id为: 11984 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,308 ERROR    ydzhang    失败: 爬取id为: 11983 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,314 ERROR    ydzhang    失败: 爬取id为: 11982 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,324 ERROR    ydzhang    失败: 爬取id为: 11981 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,330 ERROR    ydzhang    失败: 爬取id为: 11980 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,338 ERROR    ydzhang    失败: 爬取id为: 11979 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,347 ERROR    ydzhang    失败: 爬取id为: 11978 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,353 ERROR    ydzhang    失败: 爬取id为: 11977 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,360 ERROR    ydzhang    失败: 爬取id为: 11976 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,366 ERROR    ydzhang    失败: 爬取id为: 11975 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,372 ERROR    ydzhang    失败: 爬取id为: 11974 的招聘信息\n",
      "\n",
      " 41%|██████████████████████████▋                                      | 41/100 [00:01<00:01, 31.04it/s]2018-08-29 01:16:48,378 ERROR    ydzhang    失败: 爬取id为: 11973 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,384 ERROR    ydzhang    失败: 爬取id为: 11972 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,392 ERROR    ydzhang    失败: 爬取id为: 11971 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,398 ERROR    ydzhang    失败: 爬取id为: 11970 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,407 ERROR    ydzhang    失败: 爬取id为: 11969 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,414 ERROR    ydzhang    失败: 爬取id为: 11968 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,420 ERROR    ydzhang    失败: 爬取id为: 11967 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,427 ERROR    ydzhang    失败: 爬取id为: 11966 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,436 ERROR    ydzhang    失败: 爬取id为: 11965 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,443 ERROR    ydzhang    失败: 爬取id为: 11964 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,449 ERROR    ydzhang    失败: 爬取id为: 11963 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,456 ERROR    ydzhang    失败: 爬取id为: 11962 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,462 ERROR    ydzhang    失败: 爬取id为: 11961 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,469 ERROR    ydzhang    失败: 爬取id为: 11960 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,482 ERROR    ydzhang    失败: 爬取id为: 11959 的招聘信息\n",
      "\n",
      " 56%|████████████████████████████████████▍                            | 56/100 [00:01<00:01, 39.14it/s]2018-08-29 01:16:48,488 ERROR    ydzhang    失败: 爬取id为: 11958 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,494 ERROR    ydzhang    失败: 爬取id为: 11957 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,500 ERROR    ydzhang    失败: 爬取id为: 11956 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,507 ERROR    ydzhang    失败: 爬取id为: 11955 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,515 ERROR    ydzhang    失败: 爬取id为: 11954 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,521 ERROR    ydzhang    失败: 爬取id为: 11953 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,527 ERROR    ydzhang    失败: 爬取id为: 11952 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,538 ERROR    ydzhang    失败: 爬取id为: 11951 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,545 ERROR    ydzhang    失败: 爬取id为: 11950 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,551 ERROR    ydzhang    失败: 爬取id为: 11949 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,558 ERROR    ydzhang    失败: 爬取id为: 11948 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,564 ERROR    ydzhang    失败: 爬取id为: 11947 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,570 ERROR    ydzhang    失败: 爬取id为: 11946 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,578 ERROR    ydzhang    失败: 爬取id为: 11945 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,584 ERROR    ydzhang    失败: 爬取id为: 11944 的招聘信息\n",
      "\n",
      " 71%|██████████████████████████████████████████████▏                  | 71/100 [00:01<00:00, 46.34it/s]2018-08-29 01:16:48,593 ERROR    ydzhang    失败: 爬取id为: 11943 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,600 ERROR    ydzhang    失败: 爬取id为: 11942 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,606 ERROR    ydzhang    失败: 爬取id为: 11941 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,612 ERROR    ydzhang    失败: 爬取id为: 11940 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,618 ERROR    ydzhang    失败: 爬取id为: 11939 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,625 ERROR    ydzhang    失败: 爬取id为: 11938 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,631 ERROR    ydzhang    失败: 爬取id为: 11937 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,638 ERROR    ydzhang    失败: 爬取id为: 11936 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,644 ERROR    ydzhang    失败: 爬取id为: 11935 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,650 ERROR    ydzhang    失败: 爬取id为: 11934 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,657 ERROR    ydzhang    失败: 爬取id为: 11933 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,668 ERROR    ydzhang    失败: 爬取id为: 11932 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,674 ERROR    ydzhang    失败: 爬取id为: 11931 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,681 ERROR    ydzhang    失败: 爬取id为: 11930 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,688 ERROR    ydzhang    失败: 爬取id为: 11929 的招聘信息\n",
      "\n",
      " 86%|███████████████████████████████████████████████████████▉         | 86/100 [00:01<00:00, 52.57it/s]2018-08-29 01:16:48,693 ERROR    ydzhang    失败: 爬取id为: 11928 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,700 ERROR    ydzhang    失败: 爬取id为: 11927 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:48,707 ERROR    ydzhang    失败: 爬取id为: 11926 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:51,714 ERROR    ydzhang    失败: 爬取id为: 11925 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:51,720 ERROR    ydzhang    失败: 爬取id为: 11924 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:51,727 ERROR    ydzhang    失败: 爬取id为: 11923 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:51,734 ERROR    ydzhang    失败: 爬取id为: 11922 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:51,741 ERROR    ydzhang    失败: 爬取id为: 11921 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:51,757 ERROR    ydzhang    失败: 爬取id为: 11920 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:51,763 ERROR    ydzhang    失败: 爬取id为: 11919 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:51,769 ERROR    ydzhang    失败: 爬取id为: 11918 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:51,777 ERROR    ydzhang    失败: 爬取id为: 11917 的招聘信息\n",
      "\n",
      "2018-08-29 01:16:51,785 ERROR    ydzhang    失败: 爬取id为: 11916 的招聘信息\n",
      "\n",
      " 99%|████████████████████████████████████████████████████████████████▎| 99/100 [00:04<00:00, 20.92it/s]2018-08-29 01:16:51,791 ERROR    ydzhang    失败: 爬取id为: 11915 的招聘信息\n",
      "\n",
      "100%|████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 21.10it/s]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = pymysql.connect(\"39.108.157.74\",\"root\",\"00genius00\",\"JobExpress\" )\n",
    "cursor = db.cursor()\n",
    "query = 'SELECT * FROM links WHERE crawled = 0;'\n",
    "data = pd.read_sql_query(query, db)\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file                                            1286976702\n",
       "id                                                       0\n",
       "links    http://bbs.nju.edu.cn/bbscon?board=JobExpress&...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0, ['file', 'id', 'links']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file                                              1286976702\n",
       "id                                                         0\n",
       "links      http://bbs.nju.edu.cn/bbscon?board=JobExpress&...\n",
       "crawled                                                    0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(data))):\n",
    "    file, id, url = data.loc[i, ['file', 'id', 'links']]\n",
    "    user_id, user_name, clicks, title, day, month, date, time, year, text = get_details(url)\n",
    "    \n",
    "    sql_query = \"REPLACE INTO details VALUES ('%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s', '%s')\" %(str(file), str(index), url, user_id, user_name, clicks, title, day, month, date, time, year, text)\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(sql_query)\n",
    "        db.commit()\n",
    "        logger.info('成功: 插入id为: %s 的招聘信息' %str(index))\n",
    "        SUCCESSES += 1\n",
    "    except:\n",
    "        db.rollback()\n",
    "        logger.error('失败: 插入id为: %s 的招聘信息' %str(index))\n",
    "        ERRORS += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jxhnpl 孤之剑未尝不利 62 【汽车之家】商业产品/运营实习生 Tue Aug 28 09:27:10 2018  希望从事互联网行业，对商业化感兴趣的学弟学妹们不可错过~ 我们团队的实习生招聘，如果感兴趣，请邮件我简历~jiangxuehong@autohome.com.cn 岗位职责： 1、负责产品基础运营文档的维护更新； 2、承接业务部门广告投放需求，协助运营处理基础需求； 3、整理分析广告投放数据，完成日报周报等日常数据报告，协助运营同学把控广告效果； 4、协调内部资源，协助运营及产品进行线上问题处理跟进，促进产品迭代完善。 岗位要求： 1、本科及以上学历在读学生，可保证每周4个工作日及以上、连续4个月以上的实习时间； 2、对数据敏感，可以熟练操作excel、ppt等工具； 3、做事踏实认真，具备较强的快速学习能力、逻辑思维能力、执行力以及沟通协调能力； 4、有广告行业、商业化运营经验者优先。  '"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'%s %s %s %s %s %s %s %s %s %s ' %get_details(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
